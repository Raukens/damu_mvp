import logging
from typing import List, Dict, Optional, Any
from qdrant_client import QdrantClient
from qdrant_client.http import models
from sentence_transformers import SentenceTransformer
import os
from dotenv import load_dotenv

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# –ó–∞–≥—Ä—É–∑–∫–∞ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è
load_dotenv()

class QdrantRetriever:
    def __init__(
        self,
        cloud_url: Optional[str] = None,
        api_key: Optional[str] = None,
        collection_name: str = "my_documents",
        embedding_model_name: str = "sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2"
    ):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Ä–µ—Ç—Ä–∏–≤–µ—Ä–∞ –¥–ª—è Qdrant Cloud
        """
        # –ü–æ–ª—É—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –∏–∑ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è –∏–ª–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
        cloud_url = cloud_url or os.getenv("QDRANT_CLOUD_URL")
        api_key = api_key or os.getenv("QDRANT_API_KEY")
        
        if not cloud_url or not api_key:
            raise ValueError("–ù–µ–æ–±—Ö–æ–¥–∏–º–æ —É–∫–∞–∑–∞—Ç—å cloud_url –∏ api_key")
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–ª–∏–µ–Ω—Ç–∞ Qdrant Cloud
        self.client = QdrantClient(
            url=cloud_url,
            api_key=api_key,
            timeout=30
        )
        
        self.collection_name = collection_name
        
        # –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ –¥–ª—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤
        logger.info(f"–ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤: {embedding_model_name}")
        self.embedding_model = SentenceTransformer(embedding_model_name)
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è
        self._check_connection()
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤–µ—Ä—Å–∏—é API
        self._check_api_version()
    
    def _check_connection(self):
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ Qdrant"""
        try:
            collections = self.client.get_collections()
            logger.info(f"–£—Å–ø–µ—à–Ω–æ–µ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ. –î–æ—Å—Ç—É–ø–Ω—ã–µ –∫–æ–ª–ª–µ–∫—Ü–∏–∏: {[col.name for col in collections.collections]}")
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è: {e}")
            raise
    
    def _check_api_version(self):
        """–ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω—ã–µ –º–µ—Ç–æ–¥—ã API"""
        self.use_search_points = hasattr(self.client, 'search_points')
        self.use_query_points = hasattr(self.client, 'query_points')
        self.use_search = hasattr(self.client, 'search')
        
        logger.info(f"API –º–µ—Ç–æ–¥—ã –¥–æ—Å—Ç—É–ø–Ω—ã: search_points={self.use_search_points}, "
                   f"query_points={self.use_query_points}, search={self.use_search}")
    
    def search(
        self,
        query: str,
        limit: int = 10,
        score_threshold: Optional[float] = None,
        filter_conditions: Optional[Dict] = None
    ) -> List[Dict]:
        """
        –ü–æ–∏—Å–∫ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –ø–æ –∑–∞–ø—Ä–æ—Å—É
        """
        try:
            # –°–æ–∑–¥–∞–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥ –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞
            logger.info(f"–°–æ–∑–¥–∞–Ω–∏–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–∞ –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞: '{query}'")
            query_embedding = self.embedding_model.encode(query).tolist()
            
            # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º —Ñ–∏–ª—å—Ç—Ä –µ—Å–ª–∏ –µ—Å—Ç—å
            search_filter = None
            if filter_conditions:
                search_filter = self._build_filter(filter_conditions)
            
            logger.info(f"–í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –ø–æ–∏—Å–∫–∞ –≤ –∫–æ–ª–ª–µ–∫—Ü–∏–∏ '{self.collection_name}'...")
            
            # –ü—Ä–æ–±—É–µ–º —Ä–∞–∑–Ω—ã–µ –º–µ—Ç–æ–¥—ã –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏
            search_result = None
            
            # –ú–µ—Ç–æ–¥ 1: –∏—Å–ø–æ–ª—å–∑—É–µ–º search (—Å–∞–º—ã–π –Ω–æ–≤—ã–π)
            if self.use_search:
                logger.info("–ò—Å–ø–æ–ª—å–∑—É—é –º–µ—Ç–æ–¥: client.search()")
                search_result = self.client.search(
                    collection_name=self.collection_name,
                    query_vector=query_embedding,
                    limit=limit,
                    query_filter=search_filter,
                    score_threshold=score_threshold
                )
            
            # –ú–µ—Ç–æ–¥ 2: –∏—Å–ø–æ–ª—å–∑—É–µ–º search_points (—Å—Ç–∞—Ä—ã–π API)
            elif self.use_search_points:
                logger.info("–ò—Å–ø–æ–ª—å–∑—É—é –º–µ—Ç–æ–¥: client.search_points()")
                from qdrant_client.http.models import SearchRequest
                
                search_request = SearchRequest(
                    vector=query_embedding,
                    limit=limit,
                    filter=search_filter,
                    score_threshold=score_threshold
                )
                
                search_response = self.client.search_points(
                    collection_name=self.collection_name,
                    search_request=search_request
                )
                search_result = search_response.result
            
            # –ú–µ—Ç–æ–¥ 3: –∏—Å–ø–æ–ª—å–∑—É–µ–º query_points (–¥—Ä—É–≥–æ–π API)
            elif self.use_query_points:
                logger.info("–ò—Å–ø–æ–ª—å–∑—É—é –º–µ—Ç–æ–¥: client.query_points()")
                search_params = {
                    "collection_name": self.collection_name,
                    "query": query_embedding,
                    "limit": limit,
                    "with_payload": True,
                    "with_vectors": False
                }
                
                if search_filter:
                    search_params["filter"] = search_filter
                
                if score_threshold is not None:
                    search_params["score_threshold"] = score_threshold
                
                response = self.client.query_points(**search_params)
                search_result = response.points
            
            else:
                raise Exception("–ù–µ—Ç –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –º–µ—Ç–æ–¥–æ–≤ –ø–æ–∏—Å–∫–∞. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –≤–µ—Ä—Å–∏—é qdrant-client")
            
            # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
            results = self._format_search_results(search_result)
            
            logger.info(f"–ù–∞–π–¥–µ–Ω–æ {len(results)} —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö —á–∞–Ω–∫–æ–≤")
            return results
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–∏—Å–∫–µ: {e}")
            return []
    
    def _format_search_results(self, search_result) -> List[Dict]:
        """–§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –ø–æ–∏—Å–∫–∞ –≤ –µ–¥–∏–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç"""
        results = []
        
        # –ï—Å–ª–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤ –≤–∏–¥–µ —Å–ø–∏—Å–∫–∞ (–Ω–æ–≤—ã–π API)
        if isinstance(search_result, list):
            for hit in search_result:
                result = {
                    'id': hit.id,
                    'score': hit.score,
                    'content': hit.payload.get('content', ''),
                    'filename': hit.payload.get('filename', ''),
                    'document_id': hit.payload.get('document_id', ''),
                    'chunk_index': hit.payload.get('chunk_index', 0),
                    'total_chunks': hit.payload.get('total_chunks', 0),
                    'metadata': hit.payload.get('metadata', {})
                }
                results.append(result)
        
        # –ï—Å–ª–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤ –≤–∏–¥–µ –æ–±—ä–µ–∫—Ç–∞ —Å —Ç–æ—á–∫–∞–º–∏ (—Å—Ç–∞—Ä—ã–π API)
        elif hasattr(search_result, 'points'):
            for hit in search_result.points:
                result = {
                    'id': hit.id,
                    'score': hit.score,
                    'content': hit.payload.get('content', ''),
                    'filename': hit.payload.get('filename', ''),
                    'document_id': hit.payload.get('document_id', ''),
                    'chunk_index': hit.payload.get('chunk_index', 0),
                    'total_chunks': hit.payload.get('total_chunks', 0),
                    'metadata': hit.payload.get('metadata', {})
                }
                results.append(result)
        
        # –ï—Å–ª–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤ –≤–∏–¥–µ –æ–±—ä–µ–∫—Ç–∞ —Å result (–æ—á–µ–Ω—å —Å—Ç–∞—Ä—ã–π API)
        elif hasattr(search_result, 'result'):
            for hit in search_result.result:
                result = {
                    'id': hit.id,
                    'score': hit.score,
                    'content': hit.payload.get('content', ''),
                    'filename': hit.payload.get('filename', ''),
                    'document_id': hit.payload.get('document_id', ''),
                    'chunk_index': hit.payload.get('chunk_index', 0),
                    'total_chunks': hit.payload.get('total_chunks', 0),
                    'metadata': hit.payload.get('metadata', {})
                }
                results.append(result)
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ score (–ø–æ —É–±—ã–≤–∞–Ω–∏—é)
        results.sort(key=lambda x: x['score'], reverse=True)
        return results
    
    def _build_filter(self, conditions: Dict) -> Optional[models.Filter]:
        """
        –°–æ–∑–¥–∞–Ω–∏–µ —Ñ–∏–ª—å—Ç—Ä–∞ –¥–ª—è –ø–æ–∏—Å–∫–∞
        """
        if not conditions:
            return None
            
        filter_conditions = []
        
        for key, value in conditions.items():
            if isinstance(value, list):
                # –î–ª—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –ø–æ –º–∞—Å—Å–∏–≤—É –∑–Ω–∞—á–µ–Ω–∏–π
                filter_conditions.append(
                    models.FieldCondition(
                        key=f"payload.{key}",
                        match=models.MatchAny(any=value)
                    )
                )
            else:
                # –î–ª—è —Ç–æ—á–Ω–æ–≥–æ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è
                filter_conditions.append(
                    models.FieldCondition(
                        key=f"payload.{key}",
                        match=models.MatchValue(value=value)
                    )
                )
        
        return models.Filter(must=filter_conditions) if filter_conditions else None
    
    def get_collection_info(self) -> Dict:
        """
        –ü–æ–ª—É—á–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –∫–æ–ª–ª–µ–∫—Ü–∏–∏
        """
        try:
            collection_info = self.client.get_collection(self.collection_name)
            return {
                'name': collection_info.name,
                'points_count': collection_info.points_count,
                'vectors_count': collection_info.vectors_count,
                'status': collection_info.status
            }
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –∫–æ–ª–ª–µ–∫—Ü–∏–∏: {e}")
            return {}
    
    def count_points(self) -> int:
        """
        –ü–æ–ª—É—á–µ–Ω–∏–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ —Ç–æ—á–µ–∫ –≤ –∫–æ–ª–ª–µ–∫—Ü–∏–∏
        """
        try:
            count_result = self.client.count(
                collection_name=self.collection_name,
                exact=True
            )
            return count_result.count
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–¥—Å—á–µ—Ç–µ —Ç–æ—á–µ–∫: {e}")
            return 0
    
    def scroll_all_points(self, limit: int = 100) -> List[Dict]:
        """
        –ü—Ä–æ—Å–º–æ—Ç—Ä –≤—Å–µ—Ö —Ç–æ—á–µ–∫ –≤ –∫–æ–ª–ª–µ–∫—Ü–∏–∏
        """
        try:
            all_points = []
            next_page_offset = None
            
            while True:
                scroll_result = self.client.scroll(
                    collection_name=self.collection_name,
                    limit=limit,
                    offset=next_page_offset,
                    with_payload=True,
                    with_vectors=False
                )
                
                points = scroll_result[0]
                next_page_offset = scroll_result[1]
                
                for point in points:
                    all_points.append({
                        'id': point.id,
                        'payload': point.payload,
                        'score': None  # –Ω–µ—Ç —Å–∫–æ—Ä–∞ –ø—Ä–∏ —Å–∫—Ä–æ–ª–ª–µ
                    })
                
                if next_page_offset is None:
                    break
            
            return all_points
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–∫—Ä–æ–ª–ª–µ —Ç–æ—á–µ–∫: {e}")
            return []

# –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω–∞—è –≤–µ—Ä—Å–∏—è - –ø—Ä–æ—Å—Ç–æ–π –ø–æ–∏—Å–∫ –±–µ–∑ –∫–ª–∞—Å—Å–∞
def simple_search():
    """–ü—Ä–æ—Å—Ç–æ–π –ø–æ–∏—Å–∫ –±–µ–∑ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –∫–ª–∞—Å—Å–∞"""
    
    # –ü–æ–ª—É—á–∞–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∏–∑ .env
    cloud_url = os.getenv("QDRANT_CLOUD_URL")
    api_key = os.getenv("QDRANT_API_KEY")
    
    if not cloud_url or not api_key:
        print("–û—à–∏–±–∫–∞: –ù–µ –∑–∞–¥–∞–Ω—ã QDRANT_CLOUD_URL –∏ QDRANT_API_KEY –≤ .env —Ñ–∞–π–ª–µ")
        return
    
    # –ü–æ–¥–∫–ª—é—á–∞–µ–º—Å—è –∫ Qdrant
    client = QdrantClient(
        url=cloud_url,
        api_key=api_key,
        timeout=30
    )
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω—ã–µ –º–µ—Ç–æ–¥—ã
    use_search_points = hasattr(client, 'search_points')
    use_query_points = hasattr(client, 'query_points')
    use_search = hasattr(client, 'search')
    
    print(f"–î–æ—Å—Ç—É–ø–Ω—ã–µ –º–µ—Ç–æ–¥—ã: search_points={use_search_points}, query_points={use_query_points}, search={use_search}")
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å –¥–ª—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤
    print("\n–ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ –¥–ª—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤...")
    model = SentenceTransformer('sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2')
    
    # –ó–∞–ø—Ä–∞—à–∏–≤–∞–µ–º –ø–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å
    query = input("–í–≤–µ–¥–∏—Ç–µ –≤–∞—à –∑–∞–ø—Ä–æ—Å: ").strip()
    if not query:
        query = "—Å—É–±—Å–∏–¥–∏—Ä–æ–≤–∞–Ω–∏–µ"
    
    print(f"\n–ü–æ–∏—Å–∫: '{query}'")
    
    # –°–æ–∑–¥–∞–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥
    query_embedding = model.encode(query).tolist()
    
    try:
        # –ü—Ä–æ–±—É–µ–º —Ä–∞–∑–Ω—ã–µ –º–µ—Ç–æ–¥—ã –ø–æ–∏—Å–∫–∞
        search_result = None
        
        if use_search_points:
            print("–ò—Å–ø–æ–ª—å–∑—É—é –º–µ—Ç–æ–¥: search_points")
            from qdrant_client.http.models import SearchRequest
            
            search_request = SearchRequest(
                vector=query_embedding,
                limit=5,
                with_payload=True,
                with_vector=False
            )
            
            response = client.search_points(
                collection_name="my_documents",
                search_request=search_request
            )
            search_result = response.result
        
        elif use_search:
            print("–ò—Å–ø–æ–ª—å–∑—É—é –º–µ—Ç–æ–¥: search")
            search_result = client.search(
                collection_name="my_documents",
                query_vector=query_embedding,
                limit=5
            )
        
        elif use_query_points:
            print("–ò—Å–ø–æ–ª—å–∑—É—é –º–µ—Ç–æ–¥: query_points")
            response = client.query_points(
                collection_name="my_documents",
                query=query_embedding,
                limit=5,
                with_payload=True,
                with_vectors=False
            )
            search_result = response.points
        
        else:
            print("‚ùå –ù–µ—Ç –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –º–µ—Ç–æ–¥–æ–≤ –ø–æ–∏—Å–∫–∞")
            return
        
        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        if hasattr(search_result, 'result'):
            hits = search_result.result
        elif hasattr(search_result, 'points'):
            hits = search_result.points
        elif isinstance(search_result, list):
            hits = search_result
        else:
            hits = []
        
        print(f"\n‚úÖ –ù–∞–π–¥–µ–Ω–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤: {len(hits)}\n")
        
        for i, hit in enumerate(hits, 1):
            print(f"–†–µ–∑—É–ª—å—Ç–∞—Ç {i}:")
            print(f"  ID: {hit.id}")
            print(f"  –§–∞–π–ª: {hit.payload.get('filename', '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ')}")
            print(f"  –°—Ö–æ–∂–µ—Å—Ç—å: {hit.score:.3f}")
            content = hit.payload.get('content', '')
            print(f"  –ö–æ–Ω—Ç–µ–Ω—Ç: {content[:200]}..." if len(content) > 200 else f"  –ö–æ–Ω—Ç–µ–Ω—Ç: {content}")
            
            # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –µ—Å–ª–∏ –µ—Å—Ç—å
            if 'chunk_index' in hit.payload:
                print(f"  –ß–∞–Ω–∫: {hit.payload.get('chunk_index')}/{hit.payload.get('total_chunks', 1)}")
            print()
            
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–∏—Å–∫–µ: {e}")
        
        # –ü—Ä–æ–±—É–µ–º –ø–æ–ª—É—á–∏—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –∫–æ–ª–ª–µ–∫—Ü–∏–∏
        try:
            collections = client.get_collections()
            print(f"\n–î–æ—Å—Ç—É–ø–Ω—ã–µ –∫–æ–ª–ª–µ–∫—Ü–∏–∏: {[col.name for col in collections.collections]}")
            
            # –ü—Ä–æ–±—É–µ–º –¥—Ä—É–≥—É—é –∫–æ–ª–ª–µ–∫—Ü–∏—é –µ—Å–ª–∏ –µ—Å—Ç—å
            available_collections = [col.name for col in collections.collections]
            if "my_documents" not in available_collections and available_collections:
                print(f"\n–ö–æ–ª–ª–µ–∫—Ü–∏—è 'my_documents' –Ω–µ –Ω–∞–π–¥–µ–Ω–∞. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å: {available_collections[0]}")
        except Exception as e2:
            print(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Å–ø–∏—Å–æ–∫ –∫–æ–ª–ª–µ–∫—Ü–∏–π: {e2}")

# –ò–Ω—Ç–µ—Ä—Ñ–µ–π—Å –∫–æ–º–∞–Ω–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–∏
def interactive_cli():
    """–ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–π —Ä–µ–∂–∏–º –∫–æ–º–∞–Ω–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–∏"""
    
    print("ü§ñ RAG –ü–æ–∏—Å–∫ –ø–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞–º")
    print("–ö–æ–º–∞–Ω–¥—ã: 'exit' - –≤—ã—Ö–æ–¥, 'info' - –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è, 'all' - –≤—Å–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã")
    print("-" * 50)
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Ä–µ—Ç—Ä–∏–≤–µ—Ä–∞
    try:
        retriever = QdrantRetriever(collection_name="my_documents")
        print("‚úÖ –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ Qdrant Cloud —É—Å–ø–µ—à–Ω–æ!")
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –∫–æ–ª–ª–µ–∫—Ü–∏–∏
        info = retriever.get_collection_info()
        print(f"üìä –ö–æ–ª–ª–µ–∫—Ü–∏—è: {info.get('name')}")
        print(f"üìä –¢–æ—á–µ–∫ –≤ –∫–æ–ª–ª–µ–∫—Ü–∏–∏: {info.get('points_count', 'N/A')}")
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏: {e}")
        print("–ü—Ä–æ–±—É–µ–º –ø—Ä–æ—Å—Ç–æ–π —Ä–µ–∂–∏–º...")
        simple_search()
        return
    
    while True:
        command = input("\n–í–≤–µ–¥–∏—Ç–µ –∑–∞–ø—Ä–æ—Å –∏–ª–∏ –∫–æ–º–∞–Ω–¥—É: ").strip()
        
        if command.lower() in ['exit', 'quit', '–≤—ã—Ö–æ–¥']:
            print("–î–æ —Å–≤–∏–¥–∞–Ω–∏—è!")
            break
        
        elif command.lower() == 'info':
            info = retriever.get_collection_info()
            print(f"üìä –ö–æ–ª–ª–µ–∫—Ü–∏—è: {info.get('name', 'N/A')}")
            print(f"üìä –¢–æ—á–µ–∫: {info.get('points_count', 'N/A')}")
            print(f"üìä –°—Ç–∞—Ç—É—Å: {info.get('status', 'N/A')}")
        
        elif command.lower() == 'all':
            limit = input("–°–∫–æ–ª—å–∫–æ –ø–æ–∫–∞–∑–∞—Ç—å? (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 5): ").strip()
            limit = int(limit) if limit.isdigit() else 5
            
            points = retriever.scroll_all_points(limit=limit)
            print(f"\n–ü–æ–∫–∞–∑–∞–Ω–æ {len(points)} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤:")
            
            for i, point in enumerate(points, 1):
                payload = point['payload']
                print(f"\n{i}. üìÑ {payload.get('filename', '–ë–µ–∑ –∏–º–µ–Ω–∏')}")
                if 'chunk_index' in payload:
                    print(f"   –ß–∞–Ω–∫: {payload.get('chunk_index')}/{payload.get('total_chunks', 1)}")
                content = payload.get('content', '')
                print(f"   {content[:100]}..." if len(content) > 100 else f"   {content}")
        
        else:
            # –û–±—ã—á–Ω—ã–π –ø–æ–∏—Å–∫
            limit_input = input("–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 3): ").strip()
            limit = int(limit_input) if limit_input.isdigit() else 3
            
            print(f"\nüîç –ü–æ–∏—Å–∫: '{command}'...")
            results = retriever.search(command, limit=limit)
            
            if results:
                print(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ {len(results)} —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤:\n")
                
                for i, result in enumerate(results, 1):
                    print(f"{i}. üìÑ {result['filename']} (—Å—Ö–æ–∂–µ—Å—Ç—å: {result['score']:.3f})")
                    if result.get('chunk_index'):
                        print(f"   üìë –ß–∞–Ω–∫: {result['chunk_index']}/{result['total_chunks']}")
                    content = result['content']
                    print(f"   {content[:150]}..." if len(content) > 150 else f"   {content}")
                    print()
            else:
                print("‚ùå –†–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ")
                print("–ü—Ä–æ–≤–µ—Ä—å—Ç–µ:")
                print("1. –°—É—â–µ—Å—Ç–≤—É–µ—Ç –ª–∏ –∫–æ–ª–ª–µ–∫—Ü–∏—è 'my_documents'")
                print("2. –ó–∞–≥—Ä—É–∂–µ–Ω—ã –ª–∏ –¥–æ–∫—É–º–µ–Ω—Ç—ã –≤ –∫–æ–ª–ª–µ–∫—Ü–∏—é")

if __name__ == "__main__":
    # –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–≤–µ—Ä—è–µ–º –≤–µ—Ä—Å–∏—é qdrant-client
    try:
        import qdrant_client
        print(f"–í–µ—Ä—Å–∏—è qdrant-client: {qdrant_client.__version__}")
    except:
        print("–ù–µ —É–¥–∞–ª–æ—Å—å –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å –≤–µ—Ä—Å–∏—é qdrant-client")
    
    # –ü—Ä–æ—Å—Ç–æ–π —Ä–µ–∂–∏–º
    simple_search()
    
    # –ò–ª–∏ –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–π —Ä–µ–∂–∏–º
    # interactive_cli()