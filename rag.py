"""
RAG Service v2 - Ñ Query Expansion Ñ‡ÐµÑ€ÐµÐ· LLM
Ð£Ð»ÑƒÑ‡ÑˆÐµÐ½Ð½Ñ‹Ð¹ Ð¿Ð¾Ð¸ÑÐº Ð·Ð° ÑÑ‡Ñ‘Ñ‚ Ð¿ÐµÑ€ÐµÑ„Ð¾Ñ€Ð¼ÑƒÐ»Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ñ Ð·Ð°Ð¿Ñ€Ð¾ÑÐ¾Ð²
"""

import os
import json
import logging
from typing import List, Dict, Optional, Set
from dataclasses import dataclass, field
from dotenv import load_dotenv

from qdrant_client import QdrantClient
from sentence_transformers import SentenceTransformer
from openai import OpenAI

load_dotenv()

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


@dataclass
class SearchResult:
    """Ð ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚ Ð¿Ð¾Ð¸ÑÐºÐ°"""
    content: str
    filename: str
    score: float
    chapter: str
    paragraph: str
    points: List[str]
    chunk_id: str = ""


@dataclass
class RAGResponse:
    """ÐžÑ‚Ð²ÐµÑ‚ RAG ÑÐ¸ÑÑ‚ÐµÐ¼Ñ‹"""
    answer: str
    sources: List[SearchResult]
    query: str
    expanded_queries: List[str] = field(default_factory=list)


class RAGServiceV2:
    """
    RAG ÑÐµÑ€Ð²Ð¸Ñ v2 Ñ Query Expansion
    """
    
    def __init__(
        self,
        qdrant_url: Optional[str] = None,
        qdrant_api_key: Optional[str] = None,
        openai_api_key: Optional[str] = None,
        collection_name: str = "my_documents",
        embedding_model: str = "sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2",
        llm_model: str = "gpt-4o-mini"
    ):
        # Qdrant
        self.qdrant_url = qdrant_url or os.getenv("QDRANT_URL")
        self.qdrant_api_key = qdrant_api_key or os.getenv("QDRANT_API_KEY")
        self.collection_name = collection_name
        
        # OpenAI
        self.openai_api_key = openai_api_key or os.getenv("GPT_KEY")
        self.llm_model = llm_model
        
        self._init_clients()
        
        logger.info(f"Ð—Ð°Ð³Ñ€ÑƒÐ·ÐºÐ° Ð¼Ð¾Ð´ÐµÐ»Ð¸ ÑÐ¼Ð±ÐµÐ´Ð´Ð¸Ð½Ð³Ð¾Ð²: {embedding_model}")
        self.embedding_model = SentenceTransformer(embedding_model)
        
        logger.info("RAG ÑÐµÑ€Ð²Ð¸Ñ v2 Ð¸Ð½Ð¸Ñ†Ð¸Ð°Ð»Ð¸Ð·Ð¸Ñ€Ð¾Ð²Ð°Ð½")
    
    def _init_clients(self):
        """Ð˜Ð½Ð¸Ñ†Ð¸Ð°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ñ ÐºÐ»Ð¸ÐµÐ½Ñ‚Ð¾Ð²"""
        if not self.qdrant_url or not self.qdrant_api_key:
            raise ValueError("ÐÐµÐ¾Ð±Ñ…Ð¾Ð´Ð¸Ð¼Ð¾ ÑƒÐºÐ°Ð·Ð°Ñ‚ÑŒ QDRANT_URL Ð¸ QDRANT_API_KEY")
        
        if not self.openai_api_key:
            raise ValueError("ÐÐµÐ¾Ð±Ñ…Ð¾Ð´Ð¸Ð¼Ð¾ ÑƒÐºÐ°Ð·Ð°Ñ‚ÑŒ OPENAI_API_KEY")
        
        self.qdrant = QdrantClient(
            url=self.qdrant_url,
            api_key=self.qdrant_api_key,
            timeout=30
        )
        
        self.openai = OpenAI(api_key=self.openai_api_key)
    
    def expand_query(self, query: str, num_variants: int = 3) -> List[str]:
        """
        Ð Ð°ÑÑˆÐ¸Ñ€ÐµÐ½Ð¸Ðµ Ð·Ð°Ð¿Ñ€Ð¾ÑÐ° Ñ‡ÐµÑ€ÐµÐ· LLM
        Ð“ÐµÐ½ÐµÑ€Ð¸Ñ€ÑƒÐµÑ‚ Ð²Ð°Ñ€Ð¸Ð°Ð½Ñ‚Ñ‹ Ð·Ð°Ð¿Ñ€Ð¾ÑÐ° Ð´Ð»Ñ Ð»ÑƒÑ‡ÑˆÐµÐ³Ð¾ Ð¿Ð¾Ð¸ÑÐºÐ°
        """
        logger.info(f"Ð Ð°ÑÑˆÐ¸Ñ€ÐµÐ½Ð¸Ðµ Ð·Ð°Ð¿Ñ€Ð¾ÑÐ°: '{query}'")
        
        prompt = f"""Ð¢Ñ‹ Ð¿Ð¾Ð¼Ð¾Ð³Ð°ÐµÑˆÑŒ ÑƒÐ»ÑƒÑ‡ÑˆÐ¸Ñ‚ÑŒ Ð¿Ð¾Ð¸ÑÐº Ð¿Ð¾ Ð½Ð¾Ñ€Ð¼Ð°Ñ‚Ð¸Ð²Ð½Ð¾-Ð¿Ñ€Ð°Ð²Ð¾Ð²Ñ‹Ð¼ Ð°ÐºÑ‚Ð°Ð¼ Ð ÐµÑÐ¿ÑƒÐ±Ð»Ð¸ÐºÐ¸ ÐšÐ°Ð·Ð°Ñ…ÑÑ‚Ð°Ð½.

ÐŸÐ¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»ÑŒ Ð·Ð°Ð´Ð°Ð» Ð²Ð¾Ð¿Ñ€Ð¾Ñ: "{query}"

Ð¡Ð³ÐµÐ½ÐµÑ€Ð¸Ñ€ÑƒÐ¹ {num_variants} Ð°Ð»ÑŒÑ‚ÐµÑ€Ð½Ð°Ñ‚Ð¸Ð²Ð½Ñ‹Ñ… Ñ„Ð¾Ñ€Ð¼ÑƒÐ»Ð¸Ñ€Ð¾Ð²ÐºÐ¸ ÑÑ‚Ð¾Ð³Ð¾ Ð·Ð°Ð¿Ñ€Ð¾ÑÐ° Ð´Ð»Ñ Ð¿Ð¾Ð¸ÑÐºÐ° Ð² ÑŽÑ€Ð¸Ð´Ð¸Ñ‡ÐµÑÐºÐ¸Ñ… Ð´Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚Ð°Ñ….

ÐŸÐ ÐÐ’Ð˜Ð›Ð:
1. Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐ¹ ÑŽÑ€Ð¸Ð´Ð¸Ñ‡ÐµÑÐºÑƒÑŽ Ñ‚ÐµÑ€Ð¼Ð¸Ð½Ð¾Ð»Ð¾Ð³Ð¸ÑŽ ÐÐŸÐ Ð Ðš (Ð¿Ð¾Ñ€ÑÐ´Ð¾Ðº, ÑƒÑÐ»Ð¾Ð²Ð¸Ñ, Ñ‚Ñ€ÐµÐ±Ð¾Ð²Ð°Ð½Ð¸Ñ, Ð¿Ñ€ÐµÐ´Ð¾ÑÑ‚Ð°Ð²Ð»ÐµÐ½Ð¸Ðµ)
2. ÐšÐ°Ð¶Ð´Ñ‹Ð¹ Ð²Ð°Ñ€Ð¸Ð°Ð½Ñ‚ Ð´Ð¾Ð»Ð¶ÐµÐ½ Ð¸ÑÐºÐ°Ñ‚ÑŒ Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸ÑŽ Ð¿Ð¾Ð´ Ñ€Ð°Ð·Ð½Ñ‹Ð¼ ÑƒÐ³Ð»Ð¾Ð¼
3. Ð’ÐºÐ»ÑŽÑ‡Ð¸ ÐºÐ»ÑŽÑ‡ÐµÐ²Ñ‹Ðµ ÑÐ»Ð¾Ð²Ð° ÐºÐ¾Ñ‚Ð¾Ñ€Ñ‹Ðµ Ð¼Ð¾Ð³ÑƒÑ‚ Ð±Ñ‹Ñ‚ÑŒ Ð² Ð·Ð°Ð³Ð¾Ð»Ð¾Ð²ÐºÐ°Ñ… Ñ€Ð°Ð·Ð´ÐµÐ»Ð¾Ð²
4. ÐžÐ´Ð¸Ð½ Ð²Ð°Ñ€Ð¸Ð°Ð½Ñ‚ â€” Ñ€Ð°Ð·Ð³Ð¾Ð²Ð¾Ñ€Ð½Ñ‹Ð¹, Ð¾Ð´Ð¸Ð½ â€” Ñ„Ð¾Ñ€Ð¼Ð°Ð»ÑŒÐ½Ñ‹Ð¹ ÑŽÑ€Ð¸Ð´Ð¸Ñ‡ÐµÑÐºÐ¸Ð¹

Ð’ÐµÑ€Ð½Ð¸ Ð¢ÐžÐ›Ð¬ÐšÐž JSON Ð¼Ð°ÑÑÐ¸Ð² ÑÑ‚Ñ€Ð¾Ðº, Ð±ÐµÐ· Ð¿Ð¾ÑÑÐ½ÐµÐ½Ð¸Ð¹:
["Ð²Ð°Ñ€Ð¸Ð°Ð½Ñ‚ 1", "Ð²Ð°Ñ€Ð¸Ð°Ð½Ñ‚ 2", "Ð²Ð°Ñ€Ð¸Ð°Ð½Ñ‚ 3"]"""

        try:
            response = self.openai.chat.completions.create(
                model=self.llm_model,
                messages=[{"role": "user", "content": prompt}],
                temperature=0.7,
                max_tokens=300
            )
            
            result_text = response.choices[0].message.content.strip()
            
            # ÐŸÐ°Ñ€ÑÐ¸Ð¼ JSON
            # Ð£Ð±Ð¸Ñ€Ð°ÐµÐ¼ Ð²Ð¾Ð·Ð¼Ð¾Ð¶Ð½Ñ‹Ðµ markdown Ð±Ð»Ð¾ÐºÐ¸
            if result_text.startswith("```"):
                result_text = result_text.split("```")[1]
                if result_text.startswith("json"):
                    result_text = result_text[4:]
            
            variants = json.loads(result_text)
            
            # Ð”Ð¾Ð±Ð°Ð²Ð»ÑÐµÐ¼ Ð¾Ñ€Ð¸Ð³Ð¸Ð½Ð°Ð»ÑŒÐ½Ñ‹Ð¹ Ð·Ð°Ð¿Ñ€Ð¾Ñ Ð² Ð½Ð°Ñ‡Ð°Ð»Ð¾
            all_queries = [query] + variants
            
            logger.info(f"Ð¡Ð³ÐµÐ½ÐµÑ€Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¾ Ð·Ð°Ð¿Ñ€Ð¾ÑÐ¾Ð²: {len(all_queries)}")
            for i, q in enumerate(all_queries):
                logger.info(f"  {i+1}. {q}")
            
            return all_queries
            
        except Exception as e:
            logger.warning(f"ÐžÑˆÐ¸Ð±ÐºÐ° Ñ€Ð°ÑÑˆÐ¸Ñ€ÐµÐ½Ð¸Ñ Ð·Ð°Ð¿Ñ€Ð¾ÑÐ°: {e}")
            # Fallback: Ð²Ð¾Ð·Ð²Ñ€Ð°Ñ‰Ð°ÐµÐ¼ Ñ‚Ð¾Ð»ÑŒÐºÐ¾ Ð¾Ñ€Ð¸Ð³Ð¸Ð½Ð°Ð»ÑŒÐ½Ñ‹Ð¹ Ð·Ð°Ð¿Ñ€Ð¾Ñ
            return [query]
    
    def search_single(self, query: str, limit: int = 5, score_threshold: float = 0.3) -> List[SearchResult]:
        """ÐŸÐ¾Ð¸ÑÐº Ð¿Ð¾ Ð¾Ð´Ð½Ð¾Ð¼Ñƒ Ð·Ð°Ð¿Ñ€Ð¾ÑÑƒ"""
        query_embedding = self.embedding_model.encode(query).tolist()
        
        search_result = self.qdrant.query_points(
            collection_name=self.collection_name,
            query=query_embedding,
            limit=limit,
            score_threshold=score_threshold,
            with_payload=True
        )
        
        results = []
        for hit in search_result.points:
            payload = hit.payload
            result = SearchResult(
                content=payload.get('content', ''),
                filename=payload.get('filename', ''),
                score=hit.score,
                chapter=payload.get('chapter', ''),
                paragraph=payload.get('paragraph', ''),
                points=payload.get('points', []),
                chunk_id=str(hit.id)
            )
            results.append(result)
        
        return results
    
    def search_with_expansion(
        self, 
        query: str, 
        limit: int = 5, 
        score_threshold: float = 0.3,
        expand: bool = True,
        num_variants: int = 3
    ) -> tuple[List[SearchResult], List[str]]:
        """
        ÐŸÐ¾Ð¸ÑÐº Ñ Ñ€Ð°ÑÑˆÐ¸Ñ€ÐµÐ½Ð¸ÐµÐ¼ Ð·Ð°Ð¿Ñ€Ð¾ÑÐ°
        Ð’Ð¾Ð·Ð²Ñ€Ð°Ñ‰Ð°ÐµÑ‚ Ð¾Ð±ÑŠÐµÐ´Ð¸Ð½Ñ‘Ð½Ð½Ñ‹Ðµ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ñ‹ Ð¸ ÑÐ¿Ð¸ÑÐ¾Ðº Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ð½Ð½Ñ‹Ñ… Ð·Ð°Ð¿Ñ€Ð¾ÑÐ¾Ð²
        """
        if expand:
            queries = self.expand_query(query, num_variants)
        else:
            queries = [query]
        
        # Ð¡Ð¾Ð±Ð¸Ñ€Ð°ÐµÐ¼ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ñ‹ Ð¾Ñ‚ Ð²ÑÐµÑ… Ð·Ð°Ð¿Ñ€Ð¾ÑÐ¾Ð²
        all_results: Dict[str, SearchResult] = {}  # chunk_id -> result
        
        for q in queries:
            results = self.search_single(q, limit=limit, score_threshold=score_threshold)
            
            for result in results:
                chunk_id = result.chunk_id
                
                # Ð•ÑÐ»Ð¸ Ñ‡Ð°Ð½Ðº ÑƒÐ¶Ðµ Ð½Ð°Ð¹Ð´ÐµÐ½ â€” Ð±ÐµÑ€Ñ‘Ð¼ Ð»ÑƒÑ‡ÑˆÐ¸Ð¹ score
                if chunk_id in all_results:
                    if result.score > all_results[chunk_id].score:
                        all_results[chunk_id] = result
                else:
                    all_results[chunk_id] = result
        
        # Ð¡Ð¾Ñ€Ñ‚Ð¸Ñ€ÑƒÐµÐ¼ Ð¿Ð¾ score
        sorted_results = sorted(all_results.values(), key=lambda x: x.score, reverse=True)
        
        # ÐžÐ³Ñ€Ð°Ð½Ð¸Ñ‡Ð¸Ð²Ð°ÐµÐ¼ ÐºÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð¾
        final_results = sorted_results[:limit]
        
        logger.info(f"ÐÐ°Ð¹Ð´ÐµÐ½Ð¾ ÑƒÐ½Ð¸ÐºÐ°Ð»ÑŒÐ½Ñ‹Ñ… Ñ‡Ð°Ð½ÐºÐ¾Ð²: {len(all_results)}, Ð²Ð¾Ð·Ð²Ñ€Ð°Ñ‰Ð°ÐµÐ¼ Ñ‚Ð¾Ð¿-{len(final_results)}")
        
        return final_results, queries
    
    def _build_context(self, search_results: List[SearchResult]) -> str:
        """Ð¤Ð¾Ñ€Ð¼Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ðµ ÐºÐ¾Ð½Ñ‚ÐµÐºÑÑ‚Ð°"""
        if not search_results:
            return "Ð ÐµÐ»ÐµÐ²Ð°Ð½Ñ‚Ð½Ð°Ñ Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸Ñ Ð½Ðµ Ð½Ð°Ð¹Ð´ÐµÐ½Ð°."
        
        context_parts = []
        
        for i, result in enumerate(search_results, 1):
            source_info = f"[Ð˜ÑÑ‚Ð¾Ñ‡Ð½Ð¸Ðº {i} | Ð ÐµÐ»ÐµÐ²Ð°Ð½Ñ‚Ð½Ð¾ÑÑ‚ÑŒ: {result.score:.0%}]"
            if result.filename:
                source_info += f"\nÐ”Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚: {result.filename}"
            if result.chapter:
                source_info += f"\n{result.chapter}"
            if result.paragraph:
                source_info += f"\n{result.paragraph}"
            if result.points:
                source_info += f"\nÐŸÑƒÐ½ÐºÑ‚Ñ‹: {', '.join(result.points)}"
            
            context_parts.append(f"{source_info}\n\n{result.content}")
        
        return "\n\n" + "="*50 + "\n\n".join(context_parts)
    
    def _build_prompt(self, query: str, context: str, expanded_queries: List[str]) -> str:
        """Ð¤Ð¾Ñ€Ð¼Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ðµ Ð¿Ñ€Ð¾Ð¼Ð¿Ñ‚Ð°"""
        
        # ÐŸÐ¾ÐºÐ°Ð·Ñ‹Ð²Ð°ÐµÐ¼ ÐºÐ°ÐºÐ¸Ðµ Ð·Ð°Ð¿Ñ€Ð¾ÑÑ‹ Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ð»Ð¸ÑÑŒ
        queries_info = ""
        if len(expanded_queries) > 1:
            queries_info = f"""
Ð”Ð»Ñ Ð¿Ð¾Ð¸ÑÐºÐ° Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸Ð¸ Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ð»Ð¸ÑÑŒ ÑÐ»ÐµÐ´ÑƒÑŽÑ‰Ð¸Ðµ Ð²Ð°Ñ€Ð¸Ð°Ð½Ñ‚Ñ‹ Ð·Ð°Ð¿Ñ€Ð¾ÑÐ°:
{chr(10).join(f'- {q}' for q in expanded_queries)}
"""
        
        return f"""Ð¢Ñ‹ â€” ÑÐºÑÐ¿ÐµÑ€Ñ‚-ÐºÐ¾Ð½ÑÑƒÐ»ÑŒÑ‚Ð°Ð½Ñ‚ Ð¿Ð¾ Ð½Ð¾Ñ€Ð¼Ð°Ñ‚Ð¸Ð²Ð½Ð¾-Ð¿Ñ€Ð°Ð²Ð¾Ð²Ñ‹Ð¼ Ð°ÐºÑ‚Ð°Ð¼ Ð ÐµÑÐ¿ÑƒÐ±Ð»Ð¸ÐºÐ¸ ÐšÐ°Ð·Ð°Ñ…ÑÑ‚Ð°Ð½.
Ð¢Ð²Ð¾Ñ Ð·Ð°Ð´Ð°Ñ‡Ð° â€” Ð´Ð°Ð²Ð°Ñ‚ÑŒ Ñ‚Ð¾Ñ‡Ð½Ñ‹Ðµ, Ð¿Ð¾Ð»Ð½Ñ‹Ðµ Ð¸ Ð¿Ñ€Ð°ÐºÑ‚Ð¸Ñ‡ÐµÑÐºÐ¸ Ð¿Ð¾Ð»ÐµÐ·Ð½Ñ‹Ðµ Ð¾Ñ‚Ð²ÐµÑ‚Ñ‹.

ÐŸÐ ÐÐ’Ð˜Ð›Ð ÐžÐ¢Ð’Ð•Ð¢Ð:
1. ÐžÑ‚Ð²ÐµÑ‡Ð°Ð¹ Ð¡Ð¢Ð ÐžÐ“Ðž Ð½Ð° Ð¾ÑÐ½Ð¾Ð²Ðµ Ð¿Ñ€ÐµÐ´Ð¾ÑÑ‚Ð°Ð²Ð»ÐµÐ½Ð½Ð¾Ð³Ð¾ ÐºÐ¾Ð½Ñ‚ÐµÐºÑÑ‚Ð°
2. Ð¡Ñ‚Ñ€ÑƒÐºÑ‚ÑƒÑ€Ð¸Ñ€ÑƒÐ¹ Ð¾Ñ‚Ð²ÐµÑ‚: ÐºÑ€Ð°Ñ‚ÐºÐ¸Ð¹ Ð¾Ñ‚Ð²ÐµÑ‚ â†’ Ð´ÐµÑ‚Ð°Ð»Ð¸ â†’ Ð¿Ð¾ÑˆÐ°Ð³Ð¾Ð²Ñ‹Ðµ Ð´ÐµÐ¹ÑÑ‚Ð²Ð¸Ñ (ÐµÑÐ»Ð¸ Ð¿Ñ€Ð¸Ð¼ÐµÐ½Ð¸Ð¼Ð¾)
3. ÐžÐ‘Ð¯Ð—ÐÐ¢Ð•Ð›Ð¬ÐÐž ÑƒÐºÐ°Ð·Ñ‹Ð²Ð°Ð¹ Ð½Ð¾Ð¼ÐµÑ€Ð° Ð¿ÑƒÐ½ÐºÑ‚Ð¾Ð² Ð¿Ñ€Ð¸ Ñ†Ð¸Ñ‚Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ð¸ (Ð½Ð°Ð¿Ñ€Ð¸Ð¼ÐµÑ€: "ÑÐ¾Ð³Ð»Ð°ÑÐ½Ð¾ Ð¿. 23...")
4. Ð•ÑÐ»Ð¸ Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸Ð¸ Ð½ÐµÐ´Ð¾ÑÑ‚Ð°Ñ‚Ð¾Ñ‡Ð½Ð¾ â€” Ñ‡ÐµÑÑ‚Ð½Ð¾ ÑÐºÐ°Ð¶Ð¸ Ð¾Ð± ÑÑ‚Ð¾Ð¼
5. Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐ¹ Ð¿Ð¾Ð½ÑÑ‚Ð½Ñ‹Ð¹ ÑÐ·Ñ‹Ðº, Ð½Ð¾ ÑÐ¾Ñ…Ñ€Ð°Ð½ÑÐ¹ ÑŽÑ€Ð¸Ð´Ð¸Ñ‡ÐµÑÐºÑƒÑŽ Ñ‚Ð¾Ñ‡Ð½Ð¾ÑÑ‚ÑŒ
{queries_info}
ÐšÐžÐÐ¢Ð•ÐšÐ¡Ð¢ Ð˜Ð— Ð”ÐžÐšÐ£ÐœÐ•ÐÐ¢ÐžÐ’:
{context}

Ð’ÐžÐŸÐ ÐžÐ¡ ÐŸÐžÐ›Ð¬Ð—ÐžÐ’ÐÐ¢Ð•Ð›Ð¯: {query}

Ð”Ð°Ð¹ ÑÑ‚Ñ€ÑƒÐºÑ‚ÑƒÑ€Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ñ‹Ð¹ Ð¾Ñ‚Ð²ÐµÑ‚:"""
    
    def generate_answer(
        self, 
        query: str, 
        search_results: List[SearchResult],
        expanded_queries: List[str],
        temperature: float = 0.3,
        max_tokens: int = 2000
    ) -> str:
        """Ð“ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ñ Ð¾Ñ‚Ð²ÐµÑ‚Ð°"""
        context = self._build_context(search_results)
        prompt = self._build_prompt(query, context, expanded_queries)
        
        logger.info(f"Ð“ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ñ Ð¾Ñ‚Ð²ÐµÑ‚Ð° Ñ‡ÐµÑ€ÐµÐ· {self.llm_model}")
        
        response = self.openai.chat.completions.create(
            model=self.llm_model,
            messages=[{"role": "user", "content": prompt}],
            temperature=temperature,
            max_tokens=max_tokens
        )
        
        return response.choices[0].message.content
    
    def ask(
        self, 
        query: str, 
        num_chunks: int = 5,
        score_threshold: float = 0.3,
        temperature: float = 0.3,
        expand_query: bool = True,
        num_variants: int = 3
    ) -> RAGResponse:
        """
        ÐžÑÐ½Ð¾Ð²Ð½Ð¾Ð¹ Ð¼ÐµÑ‚Ð¾Ð´ Ñ Query Expansion
        
        Args:
            query: Ð’Ð¾Ð¿Ñ€Ð¾Ñ Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»Ñ
            num_chunks: ÐšÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð¾ Ñ‡Ð°Ð½ÐºÐ¾Ð² ÐºÐ¾Ð½Ñ‚ÐµÐºÑÑ‚Ð°
            score_threshold: ÐœÐ¸Ð½Ð¸Ð¼Ð°Ð»ÑŒÐ½Ñ‹Ð¹ Ð¿Ð¾Ñ€Ð¾Ð³ Ñ€ÐµÐ»ÐµÐ²Ð°Ð½Ñ‚Ð½Ð¾ÑÑ‚Ð¸
            temperature: Ð¢ÐµÐ¼Ð¿ÐµÑ€Ð°Ñ‚ÑƒÑ€Ð° Ð³ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ð¸
            expand_query: Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÑŒ Ð»Ð¸ Ñ€Ð°ÑÑˆÐ¸Ñ€ÐµÐ½Ð¸Ðµ Ð·Ð°Ð¿Ñ€Ð¾ÑÐ°
            num_variants: ÐšÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð¾ Ð²Ð°Ñ€Ð¸Ð°Ð½Ñ‚Ð¾Ð² Ð·Ð°Ð¿Ñ€Ð¾ÑÐ°
        """
        # 1. ÐŸÐ¾Ð¸ÑÐº Ñ Ñ€Ð°ÑÑˆÐ¸Ñ€ÐµÐ½Ð¸ÐµÐ¼
        search_results, expanded_queries = self.search_with_expansion(
            query=query,
            limit=num_chunks,
            score_threshold=score_threshold,
            expand=expand_query,
            num_variants=num_variants
        )
        
        # 2. Ð“ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ñ Ð¾Ñ‚Ð²ÐµÑ‚Ð°
        if search_results:
            answer = self.generate_answer(
                query=query,
                search_results=search_results,
                expanded_queries=expanded_queries,
                temperature=temperature
            )
        else:
            answer = "Ðš ÑÐ¾Ð¶Ð°Ð»ÐµÐ½Ð¸ÑŽ, Ñ Ð½Ðµ Ð½Ð°ÑˆÑ‘Ð» Ñ€ÐµÐ»ÐµÐ²Ð°Ð½Ñ‚Ð½Ð¾Ð¹ Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸Ð¸ Ð² Ð´Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚Ð°Ñ…. ÐŸÐ¾Ð¿Ñ€Ð¾Ð±ÑƒÐ¹Ñ‚Ðµ Ð¿ÐµÑ€ÐµÑ„Ð¾Ñ€Ð¼ÑƒÐ»Ð¸Ñ€Ð¾Ð²Ð°Ñ‚ÑŒ Ð²Ð¾Ð¿Ñ€Ð¾Ñ."
        
        return RAGResponse(
            answer=answer,
            sources=search_results,
            query=query,
            expanded_queries=expanded_queries
        )


def compare_modes():
    """
    Ð¡Ñ€Ð°Ð²Ð½ÐµÐ½Ð¸Ðµ Ñ€ÐµÐ¶Ð¸Ð¼Ð¾Ð²: Ñ Query Expansion Ð¸ Ð±ÐµÐ·
    """
    print("=" * 70)
    print("ðŸ”¬ Ð¡Ð ÐÐ’ÐÐ•ÐÐ˜Ð•: Query Expansion vs ÐžÐ±Ñ‹Ñ‡Ð½Ñ‹Ð¹ Ð¿Ð¾Ð¸ÑÐº")
    print("=" * 70)
    
    rag = RAGServiceV2()
    
    test_query = "ÐšÐ°Ðº Ð¿Ð¾Ð»ÑƒÑ‡Ð¸Ñ‚ÑŒ ÑÑƒÐ±ÑÐ¸Ð´Ð¸Ð¸?"
    
    # Ð‘ÐµÐ· Ñ€Ð°ÑÑˆÐ¸Ñ€ÐµÐ½Ð¸Ñ
    print("\nðŸ“Œ Ð‘Ð•Ð— Query Expansion:")
    print("-" * 50)
    results_no_expand, queries_no = rag.search_with_expansion(
        test_query, limit=5, expand=False
    )
    print(f"Ð—Ð°Ð¿Ñ€Ð¾ÑÑ‹: {queries_no}")
    for i, r in enumerate(results_no_expand, 1):
        print(f"  {i}. Score: {r.score:.3f} | {r.paragraph[:50]}...")
    
    # Ð¡ Ñ€Ð°ÑÑˆÐ¸Ñ€ÐµÐ½Ð¸ÐµÐ¼
    print("\nðŸ“Œ Ð¡ Query Expansion:")
    print("-" * 50)
    results_expand, queries_yes = rag.search_with_expansion(
        test_query, limit=5, expand=True, num_variants=3
    )
    print(f"Ð—Ð°Ð¿Ñ€Ð¾ÑÑ‹: {queries_yes}")
    for i, r in enumerate(results_expand, 1):
        print(f"  {i}. Score: {r.score:.3f} | {r.paragraph[:50]}...")
    
    # Ð¡Ñ€Ð°Ð²Ð½ÐµÐ½Ð¸Ðµ
    print("\n" + "=" * 70)
    print("ðŸ“Š Ð˜Ð¢ÐžÐ“:")
    
    best_no = results_no_expand[0].score if results_no_expand else 0
    best_yes = results_expand[0].score if results_expand else 0
    
    print(f"  Ð›ÑƒÑ‡ÑˆÐ¸Ð¹ score Ð±ÐµÐ· Ñ€Ð°ÑÑˆÐ¸Ñ€ÐµÐ½Ð¸Ñ: {best_no:.3f}")
    print(f"  Ð›ÑƒÑ‡ÑˆÐ¸Ð¹ score Ñ Ñ€Ð°ÑÑˆÐ¸Ñ€ÐµÐ½Ð¸ÐµÐ¼:  {best_yes:.3f}")
    print(f"  Ð£Ð»ÑƒÑ‡ÑˆÐµÐ½Ð¸Ðµ: +{(best_yes - best_no):.3f} ({((best_yes/best_no - 1) * 100):.1f}%)")


def interactive_mode():
    """Ð˜Ð½Ñ‚ÐµÑ€Ð°ÐºÑ‚Ð¸Ð²Ð½Ñ‹Ð¹ Ñ€ÐµÐ¶Ð¸Ð¼"""
    print("=" * 60)
    print("ðŸ¤– RAG ÐšÐ¾Ð½ÑÑƒÐ»ÑŒÑ‚Ð°Ð½Ñ‚ v2 (Ñ Query Expansion)")
    print("=" * 60)
    print("ÐšÐ¾Ð¼Ð°Ð½Ð´Ñ‹:")
    print("  'exit'    â€” Ð²Ñ‹Ñ…Ð¾Ð´")
    print("  'sources' â€” Ð¿Ð¾ÐºÐ°Ð·Ð°Ñ‚ÑŒ Ð¸ÑÑ‚Ð¾Ñ‡Ð½Ð¸ÐºÐ¸")
    print("  'simple'  â€” Ñ€ÐµÐ¶Ð¸Ð¼ Ð±ÐµÐ· Query Expansion")
    print("  'expand'  â€” Ñ€ÐµÐ¶Ð¸Ð¼ Ñ Query Expansion (Ð¿Ð¾ ÑƒÐ¼Ð¾Ð»Ñ‡Ð°Ð½Ð¸ÑŽ)")
    print("  'compare' â€” ÑÑ€Ð°Ð²Ð½Ð¸Ñ‚ÑŒ Ñ€ÐµÐ¶Ð¸Ð¼Ñ‹")
    print("-" * 60)
    
    try:
        rag = RAGServiceV2()
        print("âœ… Ð¡ÐµÑ€Ð²Ð¸Ñ Ð·Ð°Ð¿ÑƒÑ‰ÐµÐ½\n")
    except Exception as e:
        print(f"âŒ ÐžÑˆÐ¸Ð±ÐºÐ°: {e}")
        return
    
    last_response = None
    use_expansion = True
    
    while True:
        mode_indicator = "ðŸ”„" if use_expansion else "ðŸ“"
        query = input(f"\n{mode_indicator} Ð’Ð°Ñˆ Ð²Ð¾Ð¿Ñ€Ð¾Ñ: ").strip()
        
        if not query:
            continue
        
        if query.lower() in ['exit', 'quit', 'Ð²Ñ‹Ñ…Ð¾Ð´']:
            print("Ð”Ð¾ ÑÐ²Ð¸Ð´Ð°Ð½Ð¸Ñ!")
            break
        
        if query.lower() == 'simple':
            use_expansion = False
            print("âœ… Ð ÐµÐ¶Ð¸Ð¼: Ð¿Ñ€Ð¾ÑÑ‚Ð¾Ð¹ Ð¿Ð¾Ð¸ÑÐº (Ð±ÐµÐ· Query Expansion)")
            continue
        
        if query.lower() == 'expand':
            use_expansion = True
            print("âœ… Ð ÐµÐ¶Ð¸Ð¼: Ñ Query Expansion")
            continue
        
        if query.lower() == 'compare':
            compare_modes()
            continue
        
        if query.lower() == 'sources' and last_response:
            print("\nðŸ“š Ð˜ÑÑ‚Ð¾Ñ‡Ð½Ð¸ÐºÐ¸:")
            for i, source in enumerate(last_response.sources, 1):
                print(f"\n[{i}] Score: {source.score:.3f}")
                print(f"    {source.chapter}")
                print(f"    {source.paragraph}")
                print(f"    ÐŸÑƒÐ½ÐºÑ‚Ñ‹: {source.points}")
            
            if last_response.expanded_queries:
                print("\nðŸ”„ Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ð½Ð½Ñ‹Ðµ Ð·Ð°Ð¿Ñ€Ð¾ÑÑ‹:")
                for q in last_response.expanded_queries:
                    print(f"    â€¢ {q}")
            continue
        
        print("\nâ³ ÐžÐ±Ñ€Ð°Ð±Ð°Ñ‚Ñ‹Ð²Ð°ÑŽ Ð·Ð°Ð¿Ñ€Ð¾Ñ...")
        
        try:
            response = rag.ask(
                query, 
                expand_query=use_expansion,
                num_variants=3
            )
            last_response = response
            
            print(f"\nðŸ’¡ ÐžÑ‚Ð²ÐµÑ‚:\n")
            print(response.answer)
            
            print(f"\nðŸ“Ž Ð˜ÑÑ‚Ð¾Ñ‡Ð½Ð¸ÐºÐ¾Ð²: {len(response.sources)} | ", end="")
            print(f"Ð—Ð°Ð¿Ñ€Ð¾ÑÐ¾Ð²: {len(response.expanded_queries)}")
            print("   (Ð²Ð²ÐµÐ´Ð¸Ñ‚Ðµ 'sources' Ð´Ð»Ñ Ð´ÐµÑ‚Ð°Ð»ÐµÐ¹)")
                
        except Exception as e:
            print(f"âŒ ÐžÑˆÐ¸Ð±ÐºÐ°: {e}")


if __name__ == "__main__":
    import sys
    
    if len(sys.argv) > 1 and sys.argv[1] == "compare":
        compare_modes()
    else:
        interactive_mode()